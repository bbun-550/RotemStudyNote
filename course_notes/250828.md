250828

이항분류
다항분류 : $-\infty$ ~ $+\infty$ 값을 확률로 반환



로지스틱 > 퍼셉트론 > 딥러닝(이항분류, 다항분류 ; keras운영, 활성함수를 쓴다) >  

---

>실습파일
>[[logit01.py]] : 어제 내용 이어서 함
>[[logit02.py]] : 날씨 예보(강우 여부) 예측 연습
>[[logit03.py]] : 
>[[logit04_iris.py]] : iris dataset으로 다항분류

## 혼돈 행렬 confusion matrix
![[confusionmatrix.png]] - [출처](https://shinminyong.tistory.com/28)
- TP True Positive (참양성) : 모델이 맞다고 예측했고 실제도 맞다. 예측 성공
- TN True Negative (참음성) : 모델이 아니라고 예측했고 실제도 아니다. 예측 성공
- FP False Positive (거짓양성) : 모델이 맞다고 예측했고 실제는 아니다. 예측 실패, 1종 오류
- FN False Negative (거짓음성) : 모델이 아니라고 예측했고 실제는 맞다. 예측 실패, 2종 오류

- 즉, T는 모델이 예측 성공이다.

#### 정확도 Accuracy
- 전체 예측한 것 중 모델이 제대로 예측한 정도는 알 수 있다.
$$\frac{TP+TN}{TP+TP+FP+FN}$$

#### 민감도 Recall Sensitivity
- 실제가 맞았을 때, 모델이 예측 성공한 비율이다.
$$\frac{TP}{TP+FN}$$

#### 정밀도 Precision
- 모델이 맞다고 예측한 결과가 실제로 맞았는지 확인할 수 있는 지표이다.
$$\frac{TP}{TP+FP}$$

#### 특이도 Specificity

>데이터 수 많아지면 모델 성능, 정확도는 높아진다.

## 편향과 분산 tradeoff - 면접
- [참고 링크](https://bkshin.tistory.com/entry/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-12-%ED%8E%B8%ED%96%A5Bias%EC%99%80-%EB%B6%84%EC%82%B0Variance-Trade-off)
- 편향-분산 트레이드오프는 지도학습에서 에러처리할 때 중요하게 생각하는 요소이다.
- 모델이 복잡해질수록 편향은 작아지고, 분산은 커진다 ; overfitting된다.
- 모델이 단순해질수록 편향은 커지고, 분산은 작아진다. ; underfitting된다
	- 즉, 오류를 최소화하려면 편향과 분산의 합이 최소가 되는 적당한 지점을 찾아야 한다.

>[!SUMMARY] 내가 이해한 바
>편향 : 목표치와 가까울 때, 낮은 편향. 반대로 목표에서 벗어나면 높은 편향
>	예측값이 목표치에서 얼마나 멀리 떨어져 있는지 측정할 수 있다.
>분산 : 퍼져있는 정도.
>	예측값들끼리의 차이로 측정할 수 있다.

Machine Learning > tolerence 포용성
- 경험하지 않은 새로운 데이터에 잘 적용될 수 있게 좋은 모델이다.
	즉, 일반화된 모델을 만들어라

## 날씨 예보(강우 여부)
- 비가 온다/안온다가 yes/no로 되어 있기 때문에 더미데이터로 만들어준다.


## LogisticRegression 클래스 - 다항분류 가능
- softmax 쓰면 확률값으로 나온다.
```python
class sklearn.linear_model.LogisticRegression(penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='deprecated', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)
```
- `solver{‘lbfgs’, ‘liblinear’, ‘newton-cg’, ‘newton-cholesky’, ‘sag’, ‘saga’}, default=’lbfgs’`



