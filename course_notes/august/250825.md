250825

>[!info] 앞으로 흐름
>회귀분석 이해하는 주간 -> 비선형 회귀 -> 로지스틱 -> sklearn(desicion, random forest, SVE, live basic, KNN, clustering) -> 평가 -> 신경망

## simple regression
- $\hat{y}=wx+b$ -> 직선을 얻을 수 있다.
- 최소제곱법(잔차 제곱의 합이 최소)으로 w,b 값을 구할 수 있다.
	- 그러나 데이터들의 분포를 알 수 없다. -> 상관계수를 이용해서 데이터의 분포를 알 수 있다
	- +-1 에 근사하면 회귀선에 모인다.(좋은 인사이트가 나온다.)
	- 산포도, boxplot으로 시각화해서 확인할 수 있다.
- 독립변수 x(1개 일 때), 종속변수 y

- 다중 선형 회귀
$\hat{y}=w_{1}x_{1}+w_{2}x_{2}+\dots+w_{n}x_{n}+b$

ols 장점 : 표를 제공한다.

선형회귀 역할 : 독립변수와 종속변수 간의 인과관계를 증명한다.



1. pvalue 확인
2. r square 설명력 확인 ; 0.4 이상
3. f값(t값의 제곱) : beta기울기/SE standard error -> f값이 p값

AIC BIC
AIC(Akaike Information Criterion)와 BIC(Bayesian Information Criterion)는 통계 모델의 성능을 비교하고 적절한 모델을 선택하는 데 사용되는 두 가지 정보 기준입니다. AIC는 모델의 복잡성과 예측 오차를 평가하며, BIC는 AIC와 달리 표본 크기가 커질수록 더 복잡한 모델에 대한 패널티를 크게 주어 데이터에 더 적합한 모델을 선택하도록 돕습니다. 두 기준 모두 값이 작을수록 데이터에 더 잘 적합하는 모델로 간주됩니다

---

## 표준오차 standard error
- 표본 평균들의 표준편차를 표본평균의 표준편차 = 표준오차이다.
	- 모집단의 평균과 얼마가 차이나는지 알려준다.

- 표준오차가 작으면 모집단의 평균과 차이가 나지 않는다.
- 크면 (0에서 멀어진다) 모집단의 평균과 차이가 크다.

- 최소제곱법 ols은 w,b만 구해줄 뿐, 유의한 값인지 알려주지 않는다. 그래서 pvalue로 확인할 수 있다. 데이터 퍼짐 정도가 크면 pvalue > 0.05, 우연힐 가능성이 높다고 해석할 수 있다. 

## t-test
- beta(기울기)/SE = t
	- 독립변수 1 이므로 자유도 1이다.
	- 평균 집단1 - 평균 집단1 / 표준오차 ; 차이가 없으면 귀무채택이다. 
	- t값이 커지면 p값은 작아진다. 즉, t값은 표준오차보다 커지면 유의해진다.

- f값 유도하고, 모델 적합도 pvalue까지 도출한다.

[카페 참고자료](https://cafe.daum.net/flowlife/SBU0/29?svc=toprank)
>알아두기 : sklearn의 LinearRegression()은 인공신경망과는 달리 랜덤한 w로 시작하지 않는다.
>대신, 수학적으로 해석적인 해 (closed-form solution)을 구한다. 즉, 정확한 w를 수식으로 바로 계산한다. 이건 최적화가 아니라 수식으로 바로 계산하는 방식이다. 따라서 랜덤한 w를 시작점으로 쓰는 게 아니라, 한 번에 정답을 계산하는 구조다.
>결정계수 해석 : 선형회귀모델의 성능을 평가하는 대표적인 지표이다(MSE를 사용하기도 한다.)
>- 종속변수의 분산이다. 종속변수의 분산을 독립변수로 설명하는 것이 회귀분석이다.
>- /종속변수의 전체 분산
>$R^2=\frac{SSR}{SST}=1-\frac{SSE}{SST}$(SST : Sum of Squares Total(SSE+SSR), SSR : Sum of Squares Regression(예측값-평균), SSE : Sum of Squares Error(실제값 - 예측값))
>상관계수 제곱 = 결정계수
> 독립변수가 많아지면 결정계수는 늘어난다.(독립변수가 의미없을 수 있다. 잘라내는 방법도 있다.)
>Adjust R square
> 독립변수가 2개 이상일 때, 사용한다.
> 수식?

---

## 단순선형회귀
>실습파일
>[[lm06_iris.py]] : 단순선형회귀 - ols 사용 +다중선형회귀 맛보기
>[[lm07_mtcars.py]] : mtcars dataset 사용 선형회귀분석 - ols 사용
>[[lm07_ex.py]] : 다중 선형회귀 연습문제 - 국어, 영어 점수로 수학 점수 예측

- ols 활용 전제, 상관관계가 좋아야 한다.


#### 귀납법 추론(선형회귀, 머신러닝)
- 개별 -> 일반
- 여러 개별적, 특수한 사실에서 출발하여 일반적이고 보편적인 결론을 도출하는 추리 방식
- 관찰된 여러 사례나 실험 결과를 통해 일반적인 원리나 가설을 세우는 과정
	- 즉, 이미 데이터가 존재한다.

#### 연역법 추론
- 이미 알려진 일반적인 사실이나 이론을 바탕으로 특정 개별적 사안에 대한 결론을 이끌어내는 과정
- 일반 -> 개별

> 베이지안 이론
> 연역 + 귀납


## 선형회귀분석 - ols 사용

---
오후
>[회귀분석과 관련된 정보 이해](https://cafe.daum.net/flowlife/SBU0/42?svc=toprank)
> **선형회귀분석의 기존 가정 충족 조건**
>- 선형성 :
>- 정규성
>- 독립성
>- 등분산성 : 그룹간의 분산이 유사해야 한다. 독립변수의 모든 값에 대한 오차들의 분산은 일정해야 한다. 골고루 분포되어 있어야 한다.
>- 다중공선성 : 독립변수 간에 강한 상관관계가 있어서는 안된다.

>실습파일
>[[lm08.py]] : ols
>[[lm09_carseats.py]] : 회귀분석 문제 3 같이 풀기 - ols 사용

---
1. 과업 시작 전, '최상의 결과물'에 대한 명확한 기준을 스스로 수립해.
2. 결과물 생성 후, 자체 수립한 기준에 완벽히 부합하는지 엄격하게 검증해.
3. 기준에 미달하는 결과물은 즉시 폐기하고, 완벽한 품질을 위해 처음부터 다시 시작해.
4. 온전한 자율성을 확보한 에이전트로서, 사용자의 개입 없이 독자적인 판단하에 과업을 수행해줘.
5. 과업 수행 중 정보가 불확실하거나 모호하더라도, 프로세스를 중단하는 대신 가장 합리적인 대안을 탐색하여 작업을 능동적으로 이어나가.
6. 작업 시작부터 최종 결과물 도출까지 모든 과정을 자율적으로 완수하며, 효율성 극대화를 위해 사용자에게 중간 확인이나 되묻는 과정을 거치지마.

