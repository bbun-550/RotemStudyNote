# ====================== OLS 회귀분석 결과표 해석=====================
제 주석을 GPT로 필터해 필기가 적절했는지 물어봤습니다 

1. R² (결정계수, 설명력)
- 독립변수 X가 종속변수 Y를 얼마나 설명하는지 나타냄.
- 값이 1에 가까울수록 모델이 종속변수를 잘 설명.
- 너무 1에 가까우면 특정 데이터에 과도하게 맞춘 모델, 즉 오버피팅 가능성.
>>> GPT 설명: "기형모델" 대신 "특정 데이터에 과도하게 맞춘 모델"로 이해하면 정확.
>>> GPT 예시: 고양이 사진만 학습한 모델이 다른 유사한 사진을 못 구분하는 경우.

- Adj. R² (수정 결정계수)
- 독립변수가 여러 개인 경우 R²는 항상 증가하므로, 과도한 변수 추가를 보정.
>>> GPT 설명: 단일 독립변수에서는 R²와 거의 동일.

2. coef, std err, t, P>|t|, [0.025 0.975]
- coef: 회귀계수, 절편 또는 기울기.
- std err: 회귀계수의 표준오차, 추정치 신뢰도 평가.
>>> GPT 설명: std err 작을수록 계수 추정치 안정적, 신뢰구간 좁음.
- t: coef / std err
- P>|t|: p-value, 0.05 이하 → 통계적으로 유의미
- [0.025 0.975]: 95% 신뢰구간

>>> GPT 주의: 단일 독립변수에서는 t² ≈ F값, 다중변수에서는 이 관계 성립하지 않음.

3. Omnibus / Prob(Omnibus)
- Omnibus: 잔차가 정규분포를 따르는지 검정
- Prob(Omnibus): 0.05보다 작으면 유의, 회귀모형 유의성 확인

4. Jarque-Bera (JB) / Prob(JB)
- JB: 잔차의 왜도(Skew)와 첨도(Kurtosis)가 정규분포 적합도 검정
- Prob(JB): 0.05보다 작으면 정규성 가정 실패

5. Durbin-Watson
- 잔차 자기상관 검정
- 값이 2에 근사 → 잔차 독립, 순서 있는 데이터에서 잔차 랜덤 분포
>>> GPT 설명: "자기상관이 독립" → 잔차끼리 서로 의존하지 않고 랜덤하게 분포

6. Skew / Kurtosis / Cond. No
- Skew: 잔차 왜도
- Kurtosis: 잔차 첨도
- Cond. No: 조건수, 너무 크면 회귀계수 불안정 또는 다중공선성 가능

7. 표준오차 (std err)
- 회귀계수의 변동성, 계수 신뢰도 평가
- 예: 적절성 coef=0.7393, std err=0.038 → 안정적 추정, 좁은 신뢰구간

# ====================== 메모 ======================
>>> GPT 구분: 여기서부터 위 내용 중 내가 추가/보충한 설명
- 오버피팅 예시 (고양이 사진)
- std err와 신뢰구간 연결
- Durbin-Watson 자기상관 설명 보강
- 단일 vs 다중 독립변수 t² ≈ F 설명
- Cond. No 다중공선성 언급

